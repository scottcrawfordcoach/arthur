ğŸ§  ScottBot Local â€“ Unified AI Assistant & Data Recall System

A local-first AI workspace for journaling, data conversion, tagging, and semantic recall â€”
built to mirror the full ScottBot / Arthur Supabase backend.

Acts as a test rig for data persistence, context retrieval, and local RAG operations
before cloud migration.

ğŸ—ï¸ Overview

ScottBot Local is a self-contained development environment that simulates
how the Supabase-based ScottBot platform will eventually behave.
It runs entirely on localhost, with the following goals:

Convert & store data (files, notes, journal entries, etc.)

Tag & embed everything for semantic recall

Retrieve contextually relevant information during conversations

Summarize & archive chat histories and content over time

Maintain preferences & memory about the userâ€™s working style

Operate as a local AI assistant with ChatGPT-like UI and live file handling

Once complete, this project becomes your proof-of-concept for persistence, retrieval, and context chaining â€”
the backbone of both ScottBot Journal and Arthur Roundtable architectures.

ğŸ§© Tech Stack
Layer	Tool	Purpose
Frontend	React + Vite + TailwindCSS	ChatGPT-style UI with file upload and chat history
Backend	Node.js + Express	API for chat, DB, embeddings, and converter
Database	SQLite (Drizzle ORM)	Local mirror of Supabase schema
Embeddings	OpenAI Embeddings API	Local vector index for recall
Models	GPT-4o-mini (retrieval) + GPT-5 (response)	Two-stage reasoning chain
Storage	Local /buckets folders	File and output storage
Converter	Python scripts	Multi-file converter and AI metadata extractor
ğŸ§± Folder Structure
scottbot-local/
â”‚
â”œâ”€â”€ frontend/                      # React + Tailwind chat interface
â”‚   â”œâ”€â”€ src/components/
â”‚   â”‚   â”œâ”€â”€ ChatWindow.jsx
â”‚   â”‚   â”œâ”€â”€ Sidebar.jsx
â”‚   â”‚   â”œâ”€â”€ FileUpload.jsx
â”‚   â”‚   â”œâ”€â”€ PreferencesPane.jsx
â”‚   â”‚   â””â”€â”€ HistoryList.jsx
â”‚   â”œâ”€â”€ src/pages/App.jsx
â”‚   â”œâ”€â”€ src/main.jsx
â”‚   â””â”€â”€ index.html
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ server.js                  # Express app entrypoint
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ chat.js                # Handles messages + recall
â”‚   â”‚   â”œâ”€â”€ files.js               # Upload, convert, tag
â”‚   â”‚   â”œâ”€â”€ preferences.js         # User prefs CRUD
â”‚   â”‚   â”œâ”€â”€ embeddings.js          # Vector retrieval endpoints
â”‚   â”‚   â””â”€â”€ archive.js             # Summaries + compression
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ db.js                  # SQLite init via Drizzle
â”‚   â”‚   â”œâ”€â”€ embeddings.js          # OpenAI vector ops
â”‚   â”‚   â”œâ”€â”€ recallEngine.js        # Local semantic search
â”‚   â”‚   â”œâ”€â”€ summarizer.js          # Context summarization
â”‚   â”‚   â”œâ”€â”€ fileManager.js         # Local bucket operations
â”‚   â”‚   â”œâ”€â”€ chatMemory.js          # Session recall + archiving
â”‚   â”‚   â””â”€â”€ preferences.js         # Memory of user interaction style
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ schema_local.sql       # Unified schema (included)
â”‚   â”‚   â””â”€â”€ drizzle.config.ts      # Optional ORM setup
â”‚   â””â”€â”€ config.json
â”‚
â”œâ”€â”€ converter/                     # File ingestion and conversion
â”‚   â”œâ”€â”€ main.py                    # Multi-file converter
â”‚   â”œâ”€â”€ handlers/                  # Markdown, YAML, Audio, OCR, etc.
â”‚   â””â”€â”€ utils/                     # Shared helpers
â”‚
â”œâ”€â”€ buckets/                       # Local storage zones
â”‚   â”œâ”€â”€ inbox/
â”‚   â”œâ”€â”€ converted/
â”‚   â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ archive/
â”‚   â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ media/
â”‚
â”œâ”€â”€ data/db/
â”‚   â””â”€â”€ ai_local.db                # SQLite database
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ package.json
â””â”€â”€ README.md

âš™ï¸ Environment Configuration

.env

OPENAI_API_KEY=your-key-here
MODEL_FAST=gpt-4o-mini
MODEL_MAIN=gpt-5
DATABASE_URL=./data/db/ai_local.db
BUCKET_PATH=./buckets
CONVERTER_PATH=./converter

ğŸ§  Database Setup

Load the unified schema into SQLite:

sqlite3 ./data/db/ai_local.db < backend/models/schema_local.sql


This creates:

All core Supabase tables (wellness, journaling, goals, preferences, library, etc.)

All assistant extensions (files, chunks, chat sessions, embeddings, archives, etc.)

ğŸ§° Core Features
1ï¸âƒ£ Conversational Chat UI

ChatGPT-like design with pastel colors (mint/blue/cream)

Sidebar for chat history and file upload

New chat button and message threading

Editable Preferences pane (user notes, style, goals)

2ï¸âƒ£ File Handling & Conversion

Upload any file (Markdown, text, image, audio, PDF)

Assistant asks how to process it:

â€œConvert to reference fileâ€

â€œStore for safekeepingâ€

â€œUse for current query onlyâ€

Converted files written to /buckets/converted/ and indexed in DB

3ï¸âƒ£ Semantic Storage & Recall

Texts and file chunks embedded via OpenAI embeddings

Local recall engine performs cosine similarity search

GPT-4o-mini handles retrieval â†’ GPT-5 composes final answer

4ï¸âƒ£ Persistent Chat History

Each chat = assistant_chat_session

Each message stored in assistant_chat_messages

Older chats auto-summarized into assistant_archive

5ï¸âƒ£ User Preferences

Live table assistant_preferences tracks user tone, context, interaction notes

Used for contextual response shaping

6ï¸âƒ£ Local Buckets (Supabase Mirror)
Bucket	Purpose
/inbox/	Raw file uploads
/converted/	Markdown + YAML conversions
/processed/	Chunks, embeddings, JSON summaries
/archive/	Compressed chat & journal entries
/outputs/	Final exports
/media/	Images, audio, video
7ï¸âƒ£ Multi-Model Reasoning Chain
User â†’ GPT-4o-mini â†’ recall search â†’ context summary â†’ GPT-5 â†’ response


GPT-4o-mini: context selection & summarization

GPT-5: final reasoning + synthesis

Context memory stored in assistant_embeddings and assistant_relations

ğŸš€ Developer Scripts
# Install dependencies
npm install

# Run backend server (Express)
npm run server

# Run frontend (Vite)
npm run dev -- --host 0.0.0.0

# Watch Python converter for new files
python3 converter/main.py --watch ./buckets/inbox


Then open your app in browser:

http://localhost:3000


Accessible to all devices on your LAN:

http://<your-local-IP>:3000

ğŸ§® Core Data Flow
[User Uploads File]
      â†“
[buckets/inbox]
      â†“
[converter/main.py]
      â†“
[buckets/converted + assistant_files table]
      â†“
[assistant_chunks + embeddings]
      â†“
[recallEngine.js + GPT-4o-mini]
      â†“
[GPT-5 response + chat history stored]

ğŸ§­ Migration Path to Supabase
Local	Supabase	Migration
SQLite DB	Postgres	pgloader or direct import
/buckets	Supabase Storage	mirror structure
JSON embeddings	pgvector columns	direct conversion
Express routes	Edge Functions	identical logic
Local UI	Vercel	deploy /frontend
ğŸ§± Key Copilot Instructions

To GitHub Copilot or VS Code:
Scaffold the project according to this specification.

Use backend/models/schema_local.sql for database setup.

Implement an Express server with routes listed under /backend/routes.

Connect SQLite via Drizzle ORM.

Implement React + Tailwind chat interface under /frontend.

Include sidebar, file upload, chat history, and preferences pane.

Integrate OpenAI API for embeddings (text-embedding-3-small) and chat models (gpt-4o-mini, gpt-5).

Ensure all file uploads are stored in /buckets and indexed in the assistant_files table.

Wire recallEngine to search embeddings locally and return context for GPT-5 generation.

Maintain preferences and summaries in DB tables.

Result: a fully local, persistent AI assistant mirroring ScottBotâ€™s Supabase backend.

ğŸ§© Next Steps

Initialize a new repo in VS Code.

Copy this README and the schema file.

Run Copilot â€œGenerate project from README.mdâ€.

Build backend and frontend scaffolds.

Integrate your existing Python converter.

Test local persistence, retrieval, and embeddings.

Once complete, youâ€™ll have:
âœ… A self-contained ScottBot Local environment
âœ… A working semantic recall system
âœ… Full data persistence across chats, journals, and uploads
âœ… One-step migration path to Supabase Cloud

## History Explorer & Topic Cloud

- Enable the new history pane with `History` in the UI to access:
      - Smart Topic Cloud (session-mode scoring by recency Ã— frequency)
      - Virtual thread previews per topic
      - Keyword search (`/api/history/search`)
      - Full unified timeline dropdown (existing experience preserved)
- Feature flags (Vite env):

```bash
VITE_UI_TOPIC_CLOUD=1
VITE_UI_TOPIC_SEARCH=1
VITE_TOPIC_CLOUD_LIMIT=15
```

- Seed demo data for the topic cloud:

```bash
npm run test:data:seed-topic-cloud
```

## Further reading

- Unified Timeline Guide: docs/UNIFIED_TIMELINE_GUIDE.md
- Topic Cloud Spec: docs/TOPIC_CLOUD_AND_HISTORY_GUIDE.md